# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================

# Choose your LLM provider for query/inference: "ollama" or "bedrock"
LLM_PROVIDER=ollama

# Choose your embedding provider for document ingestion: "ollama" or "bedrock"
# This allows using different providers for embeddings vs inference
# Example: Use Ollama (free, local) for queries and Bedrock (better quality) for embeddings
EMBEDDING_PROVIDER=bedrock

# ============================================================================
# OLLAMA CONFIGURATION (when LLM_PROVIDER=ollama)
# ============================================================================

OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:0.5b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ============================================================================
# AWS BEDROCK CONFIGURATION (when LLM_PROVIDER=bedrock)
# ============================================================================

# AWS Region where Bedrock is available
AWS_REGION=us-east-1

# Bedrock LLM Model ID
# Note: Llama 3.2 models require cross-region inference profile (us. prefix)
# Options:
#   - us.meta.llama3-2-3b-instruct-v1:0 (Smallest & cheapest, $0.15/$0.15 per M tokens)
#   - us.meta.llama3-2-11b-instruct-v1:0 (Good balance, $0.35/$0.35 per M tokens)
#   - anthropic.claude-3-haiku-20240307-v1:0 (Best for RAG, $0.25/$1.25 per M tokens)
#   - anthropic.claude-3-5-sonnet-20240620-v1:0 (Best quality, $3/$15 per M tokens)
#   - meta.llama3-1-8b-instruct-v1:0 (Open source, $0.22/$0.22 per M tokens)
#   - meta.llama3-1-70b-instruct-v1:0 (Larger, $0.99/$0.99 per M tokens)
BEDROCK_MODEL=us.meta.llama3-2-3b-instruct-v1:0

# Bedrock Embedding Model ID
# Options:
#   - amazon.titan-embed-text-v2:0 (Default, 1024 dimensions, $0.02 per M tokens)
#   - amazon.titan-embed-text-v1 (Legacy, 1536 dimensions, $0.10 per M tokens)
#   - cohere.embed-english-v3 (1024 dimensions, $0.10 per M tokens)
BEDROCK_EMBEDDING_MODEL=amazon.titan-embed-text-v2:0

# AWS Credentials (optional - will use IAM role if on EC2)
# Leave blank to use EC2 instance role (recommended for production)
# For temporary credentials (STS), all three values are required:
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=

# ============================================================================
# CHROMADB CONFIGURATION
# ============================================================================

CHROMA_HOST=localhost
CHROMA_PORT=8001

# ============================================================================
# BACKEND CONFIGURATION
# ============================================================================

BACKEND_HOST=localhost
BACKEND_PORT=8000

# Environment: development, production, or test
ENVIRONMENT=development

# CORS allowed origins (comma-separated)
ALLOWED_ORIGINS=*

# ============================================================================
# LOGGING
# ============================================================================

LOG_LEVEL=INFO
